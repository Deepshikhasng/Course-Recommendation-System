{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0                891 non-null    int64  \n",
      " 1   course_title              891 non-null    object \n",
      " 2   course_organization       891 non-null    object \n",
      " 3   course_Certificate_type   891 non-null    object \n",
      " 4   course_rating             891 non-null    float64\n",
      " 5   course_difficulty         891 non-null    object \n",
      " 6   course_students_enrolled  891 non-null    float64\n",
      " 7   combined_text             891 non-null    object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 55.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Custom transformer for text cleaning\n",
    "# class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X, y=None):\n",
    "#         return X.apply(self._clean_text)\n",
    "    \n",
    "#     def _clean_text(self, text):\n",
    "#         text = text.lower()\n",
    "#         text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "#         text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "#         text = text.strip()\n",
    "#         return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\singh\\OneDrive\\Documents\\Course_rec\\cleaned_courses.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import re\n",
    "\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.apply(self._clean_text)\n",
    "    \n",
    "    def _clean_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.apply(self._clean_text)\n",
    "\n",
    "    def _clean_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        text = text.strip()\n",
    "        return text\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"cleaner\", TextCleaner()),\n",
    "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\"))\n",
    "])\n",
    "\n",
    "pipeline.fit(df[\"course_title\"])\n",
    "\n",
    "# ✅ Save pipeline safely\n",
    "with open(\"course_pipeline.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recommend_courses(query, top_n=5):\n",
    "#     try:\n",
    "#         # Clean & transform the input query\n",
    "#         cleaned_query = course_pipeline.named_steps[\"cleaner\"].transform(pd.Series(query))\n",
    "#         query_vector = course_pipeline.named_steps[\"tfidf\"].transform(cleaned_query)\n",
    "\n",
    "#         # Transform the course titles\n",
    "#         course_texts = course_pipeline.named_steps[\"cleaner\"].transform(df[\"course_title\"])\n",
    "#         course_vectors = course_pipeline.named_steps[\"tfidf\"].transform(course_texts)\n",
    "\n",
    "    #     # Compute similarity\n",
    "    #     sim_scores = cosine_similarity(query_vector, course_vectors).flatten()\n",
    "    #     top_indices = sim_scores.argsort()[-top_n:][::-1]\n",
    "\n",
    "    #     # Return the top recommended courses\n",
    "    #     return df.iloc[top_indices][[\n",
    "    #         \"course_title\", \n",
    "    #         \"course_organization\", \n",
    "    #         \"course_rating\", \n",
    "    #         \"course_difficulty\", \n",
    "    #         \"course_students_enrolled\"\n",
    "    #     ]]\n",
    "    # except Exception as e:\n",
    "    #     print(f\"❌ Error occurred: {e}\")\n",
    "    #     return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>course_title</th>\n",
       "      <th>course_organization</th>\n",
       "      <th>course_Certificate_type</th>\n",
       "      <th>course_rating</th>\n",
       "      <th>course_difficulty</th>\n",
       "      <th>course_students_enrolled</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134</td>\n",
       "      <td>(ISC)² Systems Security Certified Practitioner...</td>\n",
       "      <td>(ISC)²</td>\n",
       "      <td>SPECIALIZATION</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>5300.0</td>\n",
       "      <td>isc systems security certified practitioner ss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>743</td>\n",
       "      <td>A Crash Course in Causality:  Inferring Causal...</td>\n",
       "      <td>University of Pennsylvania</td>\n",
       "      <td>COURSE</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>a crash course in causality  inferring causal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>874</td>\n",
       "      <td>A Crash Course in Data Science</td>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>COURSE</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>a crash course in data science johns hopkins u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>413</td>\n",
       "      <td>A Law Student's Toolkit</td>\n",
       "      <td>Yale University</td>\n",
       "      <td>COURSE</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>91000.0</td>\n",
       "      <td>a law students toolkit yale university course ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>635</td>\n",
       "      <td>A Life of Happiness and Fulfillment</td>\n",
       "      <td>Indian School of Business</td>\n",
       "      <td>COURSE</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>320000.0</td>\n",
       "      <td>a life of happiness and fulfillment indian sch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       course_title  \\\n",
       "0         134  (ISC)² Systems Security Certified Practitioner...   \n",
       "1         743  A Crash Course in Causality:  Inferring Causal...   \n",
       "2         874                     A Crash Course in Data Science   \n",
       "3         413                            A Law Student's Toolkit   \n",
       "4         635                A Life of Happiness and Fulfillment   \n",
       "\n",
       "          course_organization course_Certificate_type  course_rating  \\\n",
       "0                      (ISC)²          SPECIALIZATION            4.7   \n",
       "1  University of Pennsylvania                  COURSE            4.7   \n",
       "2    Johns Hopkins University                  COURSE            4.5   \n",
       "3             Yale University                  COURSE            4.7   \n",
       "4   Indian School of Business                  COURSE            4.8   \n",
       "\n",
       "  course_difficulty  course_students_enrolled  \\\n",
       "0          Beginner                    5300.0   \n",
       "1      Intermediate                   17000.0   \n",
       "2             Mixed                  130000.0   \n",
       "3             Mixed                   91000.0   \n",
       "4             Mixed                  320000.0   \n",
       "\n",
       "                                       combined_text  \n",
       "0  isc systems security certified practitioner ss...  \n",
       "1  a crash course in causality  inferring causal ...  \n",
       "2  a crash course in data science johns hopkins u...  \n",
       "3  a law students toolkit yale university course ...  \n",
       "4  a life of happiness and fulfillment indian sch...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([\n",
    "#     (\"cleaner\", TextCleaner()),\n",
    "#     (\"tfidf\", TfidfVectorizer(stop_words='english'))\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.fit(df[\"course_title\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"course_pipeline.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_enrolled(x):\n",
    "#     x = str(x).lower().replace('k', '')\n",
    "#     try:\n",
    "#         return float(x) * 1000\n",
    "#     except:\n",
    "#         return 0\n",
    "\n",
    "# df[\"course_students_enrolled\"] = df[\"course_students_enrolled\"].apply(convert_enrolled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(text):\n",
    "#     import re\n",
    "#     text = str(text).lower()\n",
    "#     text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "#     return text\n",
    "\n",
    "# df[\"combined_text\"] = (\n",
    "#     df[\"course_title\"] + \" \" +\n",
    "#     df[\"course_organization\"] + \" \" +\n",
    "#     df[\"course_Certificate_type\"] + \" \" +\n",
    "#     df[\"course_difficulty\"]\n",
    "# ).apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
